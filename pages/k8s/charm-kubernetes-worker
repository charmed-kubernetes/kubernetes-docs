---
wrapper_template: "kubernetes/docs/base_docs.html"
markdown_includes:
  nav: "kubernetes/docs/shared/_side-navigation.md"
context:
  title: "kubernetes-worker charm"
  description: Etcd Charm reference
keywords: kubernetes-worker, charm, config
tags: [reference]
sidebar: k8smain-sidebar
permalink: charm-kubernetes-worker.html
layout: [base, ubuntu-com]
toc: False
---

The `kubernetes-worker` charm xxxxxxxxxxxxxxxx xx x xxxxxxxxxxxxxxxxxxxxxxxx xx
xxx xxxx xxx xxxxxx xx xxxxxx xxxxx xxxxxx xxxxx xxx

## kubernetes-worker charm configuration

!-- CONFIG STARTS -->
<!--AUTOGENERATED CONFIG TEXT - DO NOT EDIT -->

### allow-privileged

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: true

This option is now deprecated and has no effect.

---

### channel

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 1.16/stable

Snap channel to install Kubernetes worker services from

---

### default-backend-image

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: auto

Docker image to use for the default backend. Auto will select an image
based on architecture.

---

### ingress

**Type**: boolean &nbsp;&nbsp;&nbsp; **Default**: True

Deploy the default http backend and ingress controller to handle
ingress requests.

---

### ingress-ssl-chain-completion

**Type**: boolean &nbsp;&nbsp;&nbsp; **Default**: False

Enable chain completion for TLS certificates used by the nginx ingress
controller.  Set this to true if you would like the ingress controller
to attempt auto-retrieval of intermediate certificates.  The default
(false) is recommended for all production kubernetes installations, and
any environment which does not have outbound Internet access.

---

### ingress-ssl-passthrough

**Type**: boolean &nbsp;&nbsp;&nbsp; **Default**: False

Enable ssl passthrough on ingress server. This allows passing the ssl
connection through to the workloads and not terminating it at the ingress
controller.

---

### kubelet-extra-args

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 

Space separated list of flags and key=value pairs that will be passed as arguments to
kubelet. For example a value like this:
  runtime-config=batch/v2alpha1=true profiling=true
will result in kubelet being run with the following options:
  --runtime-config=batch/v2alpha1=true --profiling=true
Note: As of Kubernetes 1.10.x, many of Kubelet's args have been deprecated, and can
be set with kubelet-extra-config instead.

---

### kubelet-extra-config

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: {}

Extra configuration to be passed to kubelet. Any values specified in this
config will be merged into a KubeletConfiguration file that is passed to
the kubelet service via the --config flag. This can be used to override
values provided by the charm.

Requires Kubernetes 1.10+.

The value for this config must be a YAML mapping that can be safely
merged with a KubeletConfiguration file. For example:
  {evictionHard: {memory.available: 200Mi}}

For more information about KubeletConfiguration, see upstream docs:
https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/

---

### labels

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 

Labels can be used to organize and to select subsets of nodes in the
cluster. Declare node labels in key=value format, separated by spaces.

---

### nagios_context

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: juju

Used by the nrpe subordinate charms.
A string that will be prepended to instance name to set the host name
in nagios. So for instance the hostname would be something like:
    juju-myservice-0
If you're running multiple environments with the same services in them
this allows you to differentiate between them.

---

### nagios_servicegroups

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 

A comma-separated list of nagios servicegroups.
If left empty, the nagios_context will be used as the servicegroup

---

### nginx-image

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: auto

Docker image to use for the nginx ingress controller. Auto will select an image
based on architecture.

---

### proxy-extra-args

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 

Space separated list of flags and key=value pairs that will be passed as arguments to
kube-proxy. For example a value like this:
  runtime-config=batch/v2alpha1=true profiling=true
will result in kube-apiserver being run with the following options:
  --runtime-config=batch/v2alpha1=true --profiling=true

---

### require-manual-upgrade

**Type**: boolean &nbsp;&nbsp;&nbsp; **Default**: True

When true, worker services will not be upgraded until the user triggers
it manually by running the upgrade action.

---

### snap_proxy

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 

DEPRECATED. Use snap-http-proxy and snap-https-proxy model configuration settings. HTTP/HTTPS web proxy for Snappy to use when accessing the snap store.

---

### snap_proxy_url

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: 

DEPRECATED. Use snap-store-proxy model configuration setting. The address of a Snap Store Proxy to use for snaps e.g. http://snap-proxy.example.com

---

### snapd_refresh

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: max

How often snapd handles updates for installed snaps. Setting an empty
string will check 4x per day. Set to "max" to delay the refresh as long
as possible. You may also set a custom string as described in the
'refresh.timer' section here:
  https://forum.snapcraft.io/t/system-options/87

---

### sysctl

**Type**: string &nbsp;&nbsp;&nbsp; **Default**: { net.ipv4.conf.all.forwarding : 1, net.ipv4.neigh.default.gc_thresh1 : 128, net.ipv4.neigh.default.gc_thresh2 : 28672, net.ipv4.neigh.default.gc_thresh3 : 32768, net.ipv6.neigh.default.gc_thresh1 : 128, net.ipv6.neigh.default.gc_thresh2 : 28672, net.ipv6.neigh.default.gc_thresh3 : 32768, fs.inotify.max_user_instances : 8192, fs.inotify.max_user_watches: 1048576 }

YAML formatted associative array of sysctl values, e.g.:
'{kernel.pid_max : 4194303 }'. Note that kube-proxy handles
the conntrack settings. The proper way to alter them is to
use the proxy-extra-args config to set them, e.g.:
  juju config kubernetes-master proxy-extra-args="conntrack-min=1000000 conntrack-max-per-core=250000"
  juju config kubernetes-worker proxy-extra-args="conntrack-min=1000000 conntrack-max-per-core=250000"
The proxy-extra-args conntrack-min and conntrack-max-per-core can be set to 0 to ignore
kube-proxy's settings and use the sysctl settings instead. Note the fundamental difference between
the setting of conntrack-max-per-core vs nf_conntrack_max.

---


<!-- CONFIG ENDS -->




## kubernetes-worker charm actions


## <Specific topics, etc> 
